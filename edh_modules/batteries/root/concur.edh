
/**
 * schedule a number of tasks to run concurrently, but with
 * concurrency limit specified by 'c'
 *
 * each task must be a nullary procedure (i.e. a niladic 
 * computation)
 *
 * pass 'runtime.debug' or even 'runtime.info' as 'dbgLogger'
 * to see verbose log of the finishing up
 */
method concur(*tasks, c=6, dbgLogger=0) {
  null(tasks) -> return nil
  c < 1 -> error("Invalid concurrency: " ++ c)

  // event sink for decreased number of running tasks, this will
  // read zero after all done. only start to fire after all tasks 
  // have been put to running, and the running count drops below
  // c, i.e. started to finish up
  doneSig = sink

  // use a class to manage running state (count of running tasks)
  // as instance attributes
  class Scheduler(tasks) {
    n = 0 // this somewhat emulates a WaitGroup in Go
    method scheduleMore() {
      {()} -> // no more tasks in backlog, this is a branch, 
              // so rest code in the method will be skipped
        doneSig <- this.n
      // snoc this.tasks within an atomic transaction
      ai case this.tasks of { t => rest } -> {
        this.tasks = rest // one task taken out of backlog
        fallthrough // leave the atoiso block and continue
      }
      go {
        // use `defer` to always run upon thread termination,
        // this is necessary as code after `t()` may not get to
        // run in case this thread is broken by an event reactor
        // registered during `t()`
        defer {
          this.n -= 1 // this is atomic in Edh
          if this.n < c then this.scheduleMore()
        }
        t()
      }
      // similar to WaitGroup.Add() in Go
      this.n += 1 // this is atomic in Edh
    }
  }

  schd = Scheduler(tasks)
  while not null(schd.tasks) && schd.n < c
    schd.scheduleMore()
  
  for n from doneSig do if n < 1 then return nil else
    dbgLogger <| 'finishing up concur tasks, ' ++ n ++ ' left running.'
}
